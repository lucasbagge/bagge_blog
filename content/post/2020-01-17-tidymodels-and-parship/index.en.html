---
title: Tidymodels, Random Forest og parsnip  
author: Lucas Bagge
date: '2020-02-17'
slug: tidymodels-and-parsnip
categories:
  - logistic regression
  - random forest
  - tidymodels
  - parship
tags:
  - tidymodels
  - ML
  - parship
  - random forest
subtitle: ''
summary: ''
authors: []
lastmod: '2020-05-17T20:19:54+02:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

<script src="{{< blogdown/postref >}}index.en_files/header-attrs/header-attrs.js"></script>


<div id="introduktion" class="section level2">
<h2>Introduktion</h2>
<p>I denne post vil jeg kigger på to modeller.
Den <strong>logistiske regression</strong> og <strong>random forest</strong>, hvor de begge bliver brugtblog
som klassifikations modeller.</p>
<p>Jeg kommer til at gennemgå og beskrive Random Forest da det er en model,
som er forholdsvis ny for mig og der er nogle teoretiske framwork jeg gerne
vil prøve at forklare.</p>
<p>Desuden kommer vi til at stifte bekendtskab med <code>parsnip</code> som gør det let at
skifte om til de forskellige modeller. Med det nye framwork fra
<code>tidymodels</code> kan man skifte utrolig let fra <code>glm</code> til en <strong>cross validated</strong>
random forest med <code>ranger</code>
med få linjers koder.</p>
</div>
<div id="random-forest" class="section level2">
<h2>Random forest</h2>
<p>Det er en af de mest populære machine learning algoritmer og kan både bruges
som en regresssion og klassifikation model.</p>
<p>Som navnet antyder så laver algoritmen en skov med forskellige beslutningstræer.
Desto flere træer desto mere robust er modellen. Navnet random kommer grundet to koncepter</p>
<ol style="list-style-type: decimal">
<li>Et randomiseret sample af trænings data, når man bygger hver enkelt træ.</li>
<li>Et randomiseret subsæt af features, når man splitter noder.</li>
</ol>
<p>Når vi træer hver træ så lærer den fra et random sample af data punkter.
Samples er trukket med erstatning, som kaldes <strong>bootstrapping</strong>, som betyder
at et sample vil blive brugt flere gange i et enkelt træ. Ideen er at ved at
træne hver træ med forskellige samples, så vil vi få en lavere varians og
ikke få et højere bias.</p>
<p>Ens prediction fås ved at tage gennmsnittet af predictor for hver beslutningstræ.
Denne procedure kaldes for <strong>bagging</strong>.</p>
<p>Fordele er man kan bruge den som klassifikation og regression. Den vil ikke overfitte.
Den kan håndtere store datasæt med mange dimensioner.</p>
<p>Ulemper er den ikke er så god til regressioner. Den er ikke god til at forudsige.
Der er heller ikke meget kontrol over modellen.</p>
<p>Dog er modellen anvendelig i mange sektor såsom banker, forsikringsselskaber,
forretninger somkan bruges til at finde de loyolae kunder. Den kan også bruges i
aktiemarkedet til ast finde opførelsen af en aktie.</p>
</div>
<div id="data" class="section level2">
<h2>Data</h2>
<p>I dette projekt bruger jeg data
fra Telco Customer Churn. Data indeholder 7043 rækker som hver repræsentere en kunde.
Der er 21 kolonner som er mulige predictor, der giver information til vi kan
forecast opførelse og give indsigt på forebyggelsesprogrammer.</p>
<p><code>Churn</code> er den afhængige variable og viser om kunden har forladt virksomheden
indenfor den seneste måned.</p>
<p>Jeg bruger funnktionen <code>skim</code> til at skabe et overblik over mit data.</p>
<pre class="r"><code>telco &lt;- readr::read_csv(&quot;https://raw.githubusercontent.com/treselle-systems/customer_churn_analysis/master/WA_Fn-UseC_-Telco-Customer-Churn.csv&quot;)
telco %&gt;% 
  skimr::skim()</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-1">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">Piped data</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">7043</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">21</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">17</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">customerID</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">10</td>
<td align="right">10</td>
<td align="right">0</td>
<td align="right">7043</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">gender</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">6</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">Partner</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Dependents</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">PhoneService</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">MultipleLines</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">16</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">InternetService</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">11</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">OnlineSecurity</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">19</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">OnlineBackup</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">19</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">DeviceProtection</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">19</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">TechSupport</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">19</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">StreamingTV</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">19</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">StreamingMovies</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">19</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Contract</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">8</td>
<td align="right">14</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">PaperlessBilling</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">PaymentMethod</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">12</td>
<td align="right">25</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">Churn</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">SeniorCitizen</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.16</td>
<td align="right">0.37</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">1.00</td>
<td align="left">▇▁▁▁▂</td>
</tr>
<tr class="even">
<td align="left">tenure</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">32.37</td>
<td align="right">24.56</td>
<td align="right">0.00</td>
<td align="right">9.00</td>
<td align="right">29.00</td>
<td align="right">55.00</td>
<td align="right">72.00</td>
<td align="left">▇▃▃▃▆</td>
</tr>
<tr class="odd">
<td align="left">MonthlyCharges</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">64.76</td>
<td align="right">30.09</td>
<td align="right">18.25</td>
<td align="right">35.50</td>
<td align="right">70.35</td>
<td align="right">89.85</td>
<td align="right">118.75</td>
<td align="left">▇▅▆▇▅</td>
</tr>
<tr class="even">
<td align="left">TotalCharges</td>
<td align="right">11</td>
<td align="right">1</td>
<td align="right">2283.30</td>
<td align="right">2266.77</td>
<td align="right">18.80</td>
<td align="right">401.45</td>
<td align="right">1397.47</td>
<td align="right">3794.74</td>
<td align="right">8684.80</td>
<td align="left">▇▂▂▂▁</td>
</tr>
</tbody>
</table>
<p>Her er en række ting at lægge mærke til her.</p>
<ul>
<li><strong>customerID</strong> er en unik id for hver række og af den grund har den ingen
deskriptiv eller predictive power og den skal fjernes.</li>
<li>Der er meget få <strong>NA</strong> værdier, så de kan jeg tillade mig at slette.</li>
</ul>
<pre class="r"><code>telco &lt;- telco %&gt;% 
  select(-customerID) %&gt;% 
  drop_na()</code></pre>
</div>
<div id="modellering-med-tidymodels" class="section level2">
<h2>Modellering med <code>tidymodels</code></h2>
<p>Denne post giver også en introduktion til tidymodels. Derfor vil modellen
være simpel og kommer til at bestå af <strong>logistic regression</strong> model uden meget
data bearbejdring.</p>
</div>
<div id="train-and-test-split" class="section level2">
<h2>Train and test split</h2>
<p><code>rsample()</code> kan bruges til at lave en randomiserede træning og test data,
som selvfølgelig er konstrueret udfra vores orginale telco data.</p>
<pre class="r"><code>set.seed(1972)

train_test_split &lt;- rsample::initial_split(
  data = telco,
  prop = 0.8
)
train_test_split</code></pre>
<pre><code>## &lt;Analysis/Assess/Total&gt;
## &lt;5626/1406/7032&gt;</code></pre>
<p>Ud fra ovenstående har vi at de 7032 kunder er blevet delt ud, og de 5626 er blevet
sat i træningssættet. Vi gemmer dem ned i deres eget data frame;</p>
<pre class="r"><code>train_tbl &lt;- train_test_split %&gt;% training() %&gt;% 
  unnest()
test_tbl &lt;- train_test_split %&gt;% testing()</code></pre>
</div>
<div id="en-bage-opskrift" class="section level2">
<h2>En bage opskrift</h2>
<p>For at lave en del af arbejde for at bygge modellen bruger vi <code>recipe()</code>. Denne
pakke bruger <em>bage metafor</em> til at behandle data og foretage diverse præprocessor
såsom, missing values, fjerne predictor, centering og scaling osv..</p>
<p>Det første man gør er at definere <code>recipe</code> og de transformationer man vil bruge
på ens data. Der er ikke meget at gøre i dette tilfælde, udover at tranaformerer
til faktor.</p>
<pre class="r"><code>recipe_simple &lt;- function(dataset) {
  recipe(Churn ~ ., data = dataset) %&gt;% 
    step_string2factor(all_nominal(), -all_outcomes()) %&gt;% 
    prep(data = dataset)
}</code></pre>
<p>For at undgår man vi har en <strong>data lækage</strong> (oveføre information mellem træning
og test data), skal data være ‘prepped’ ved
kun at bruge <code>train_tbl</code>.</p>
<pre class="r"><code>recipe_prepped &lt;- recipe_simple(dataset = train_tbl)</code></pre>
<p>Som den sidste del så skal vi <em>bage opskriften</em> for at alle præprocessor
bliver inkluderet i data sættene.</p>
<pre class="r"><code>train_baked &lt;- bake(recipe_prepped, new_data = train_tbl)
test_baked &lt;- bake(recipe_prepped, new_data = test_tbl)</code></pre>
</div>
<div id="fit-modellen" class="section level2">
<h2>Fit modellen</h2>
<p><code>Tidymodels</code> er det helt nye indspark fra tidyverse folkene på at skabe et framwork
for machine learning.
Hertil er der blevet lavet en del justeringer og nye pakker. En central pakke i
dette framwork er <code>parsnip</code>,som skaber en adgang til mange machine learning pakker
uden man skal kunne syntaksen til dem alle.</p>
<p>Man skal følge tre trin:</p>
<ol style="list-style-type: decimal">
<li>Bestem <strong>typen af modellen</strong> og <strong>mode</strong>.</li>
<li>Bestem <strong>engine</strong>.</li>
<li>Bestem model specifikationer og data der skal bruges.</li>
</ol>
<pre class="r"><code>logistic_glm &lt;- logistic_reg(mode = &quot;classification&quot;) %&gt;% 
  set_engine(&quot;glm&quot;) %&gt;% 
  fit(Churn ~ .,
      data = train_baked)</code></pre>
<p>Som sagt så kan du vælge en masse andre engine. I dette tilfælde hvor vi bruge en
logistisk regression, så kan vi vælge; <code>glm</code>, <code>glmnet</code>, <code>stan</code>, <code>spark</code> og <code>keras</code>.
Det smarte er vi bare kan skifte det ud og så klare parsnip transitionen.</p>
</div>
<div id="hvor-godt-klare-modellen-sig" class="section level2">
<h2>Hvor godt klare modellen sig?</h2>
<p>Det er væsentlig at se hvor god modellen er og her bruger vi pakken
<code>yardstick</code>, som gør det let at beregne forskellige måleværktøjer.
Før man kan beregne disse måle enheder skal vi beregne nogle
predictor ved at bruge <code>test_baked</code> til predict funktionen.</p>
<pre class="r"><code>prediction_glm &lt;- logistic_glm %&gt;% 
  predict(new_data = test_baked) %&gt;%
  bind_cols(test_baked %&gt;%  select(Churn))

head(prediction_glm)</code></pre>
<pre><code>## # A tibble: 6 x 2
##   .pred_class Churn
##   &lt;fct&gt;       &lt;fct&gt;
## 1 Yes         No   
## 2 No          No   
## 3 No          No   
## 4 No          No   
## 5 No          No   
## 6 No          No</code></pre>
<p>Der kan benyttes mange matricer til at undersøge hvor god modellen er,
men fokus for denne post bliver <strong>accuracy</strong>, <strong>precision</strong>, <strong>recall</strong> og <strong>F1_score</strong>.</p>
<p>Disse mål bliver udledt af <strong>Confusion Matrix</strong>, som er en tabel der beskriver
hvor godt ens klassifikations model klarer sig. Denne matrice er i sig selv ikke svær at
forstå, da den angiver antallet af; <em>false positives</em>, <em>false negatives</em>, <em>true positives</em>
og <em>true negatives</em>. Dog er nogle af målene, som udledes herfra svære koncepter og kræver
reflektion for at forstå deres betydning.</p>
<pre class="r"><code>prediction_glm %&gt;% 
  conf_mat(Churn, .pred_class) %&gt;% 
  pluck(1) %&gt;% 
  as_tibble() %&gt;% 
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), colour = &quot;white&quot;, alpha = 0.5, size = 12)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-10-1.png" width="2400" /></p>
<p>Modellen <strong>Accuracy</strong> er andel af prediction modellen ramte plet og kan udregnes ved at
lade predictions_glm gå gennem metrics funktionen. Dog er den ikke så troværdig, hvis
ens data er ubalanceret.</p>
<pre class="r"><code>prediction_glm %&gt;% 
  metrics(Churn, .pred_class) %&gt;% 
  select(-.estimator) %&gt;% 
  filter(.metric == &quot;accuracy&quot;)</code></pre>
<pre><code>## # A tibble: 1 x 2
##   .metric  .estimate
##   &lt;chr&gt;        &lt;dbl&gt;
## 1 accuracy     0.806</code></pre>
<p>Modellen får altså en score på 78%.</p>
<p><strong>Precision</strong> målser hvor sensitiv modellen er overfor False Positive, mens
Recall ser hvor sensitiv modellen er for False Negative.</p>
<p>Disse metricer er meget vigtig informationer for virksomheder fordi man så kan
forudsige hvilke kunder der er i en risiko gruppe for at forlade forretningen.
Herfra kan man så benytte sig af en fastholdessstrategi. Desuen kan
man bruge oplysning til ikke at bruge penge på kudner der alligevel
har tænkt sig at forlade virksomheden.</p>
<pre class="r"><code>tibble(
  &quot;precision&quot; =
    precision(prediction_glm, Churn, .pred_class) %&gt;% 
    select(.estimate),
  &quot;recall&quot; =
    recall(prediction_glm, Churn, .pred_class) %&gt;% 
    select(.estimate)
) %&gt;% 
  unnest() %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">precision</th>
<th align="right">recall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.8466368</td>
<td align="right">0.9024857</td>
</tr>
</tbody>
</table>
<p>Den anden og sidste populær måleværktøj er F1_score, som er det harmoniske gennemsnit
af precision og recall. Den perfekte score på 1 fås når precision og recall er perfekte.</p>
<pre class="r"><code>prediction_glm %&gt;%
  f_meas(Churn, .pred_class) %&gt;%
  select(-.estimator) %&gt;%
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">.metric</th>
<th align="right">.estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">f_meas</td>
<td align="right">0.8736696</td>
</tr>
</tbody>
</table>
</div>
<div id="fra-logitstik-regression-til-random-forest" class="section level2">
<h2>Fra logitstik regression til Random Forest</h2>
<p>Det er utrolig simpel at skifte ens model ud med en anden. Den tidligere
anvendte logistisk regressions model kan vi hurtig skifte ud med en <strong>Random
Forest</strong> model med <code>ranger</code>.</p>
</div>
<div id="croos-validation-sæt-op" class="section level2">
<h2>Croos validation sæt op</h2>
<p>For at styke modellens prediktive kræft kan man foretage cross validation, som
tit bliver sat op med 10 folder. Det kan implementeres med <code>vfold_cv()</code> fra <code>rsample</code>,
som splitter det initale trænings data.</p>
<pre class="r"><code>set.seed(123)
cross_val_tbl &lt;- 
   vfold_cv(train_tbl, v = 10)</code></pre>
<p>Vi kan genkende de 5626 fra vores tærningssæt. I hver runde vil 563 observationer
blive brugt til validere modellen for det specifikke fold.</p>
<p>For at ikke blive forvirret over bruget af initial træsning/test split til det
man bruger i cross validation benytter man begreberne <code>analysis</code> (estimer modellen)
og <code>assessment</code> (valider estimater).</p>
</div>
<div id="opdater-recipe" class="section level2">
<h2>Opdater recipe</h2>
<p>For at bruge Random Forest skal alle numeriske værdier være centred og scaled
og alle faktor skal være dummies.</p>
<pre class="r"><code>split &lt;- initial_split(telco, prop = 0.8)
train_data &lt;- training(split)
test_data &lt;- testing(split)</code></pre>
<p>For at skifte over til en anden model er utroligt simepel. Her ændre vi til
random forest i typen af modellen og tilføjer dens hyperparameter.</p>
<p>For at gøre processen lidt hurtigere propper jeg det hele i en funktion, som
estimer modellen på tværs af alle folder og retuner det i en tibble. Desuden skal
der tilføjes et skridt mere for at vi mapper de forskellige folder.</p>
<pre class="r"><code>recipe_rf &lt;- function(dataset) {
  recipe(Churn ~ ., data = dataset) %&gt;%
    step_string2factor(all_nominal(), -all_outcomes()) %&gt;%
    step_dummy(all_nominal(), -all_outcomes()) %&gt;%
    step_center(all_numeric()) %&gt;%
    step_scale(all_numeric()) %&gt;%
    prep(data = dataset)
}

rf_fun &lt;- function(split, id, try, tree) {
   
  analysis_set &lt;- split %&gt;% analysis()
  analysis_prepped &lt;- analysis_set %&gt;% recipe_rf()
  analysis_baked &lt;- analysis_prepped %&gt;% bake(new_data = analysis_set)
  model_rf &lt;-
    rand_forest(
      mode = &quot;classification&quot;,
      mtry = try,
      trees = tree
    ) %&gt;%
    set_engine(&quot;ranger&quot;,
      importance = &quot;impurity&quot;
    ) %&gt;%
    fit(Churn ~ ., data = analysis_baked)
  assessment_set &lt;- split %&gt;% assessment()
  assessment_prepped &lt;- assessment_set %&gt;% recipe_rf()
  assessment_baked &lt;- assessment_prepped %&gt;% bake(new_data = assessment_set)
  tibble(
    &quot;id&quot; = id,
    &quot;truth&quot; = assessment_baked$Churn,
    &quot;prediction&quot; = model_rf %&gt;%
      predict(new_data = assessment_baked) %&gt;%
      unlist()
  )
  
}

pred_rf &lt;- map2_df(
  .x = cross_val_tbl$splits,
  .y = cross_val_tbl$id,
  ~ rf_fun(split = .x, id = .y, try = 3, tree = 200)
)
head(pred_rf)  </code></pre>
<pre><code>## # A tibble: 6 x 3
##   id     truth prediction
##   &lt;chr&gt;  &lt;fct&gt; &lt;fct&gt;     
## 1 Fold01 Yes   No        
## 2 Fold01 Yes   Yes       
## 3 Fold01 No    No        
## 4 Fold01 No    No        
## 5 Fold01 No    No        
## 6 Fold01 No    No</code></pre>
<pre class="r"><code>pred_rf %&gt;%
  conf_mat(truth, prediction) %&gt;%
  summary() %&gt;%
  select(-.estimator) %&gt;%
  filter(.metric %in%
    c(&quot;accuracy&quot;, &quot;precision&quot;, &quot;recall&quot;, &quot;f_meas&quot;)) %&gt;%
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">.metric</th>
<th align="right">.estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">accuracy</td>
<td align="right">0.7996801</td>
</tr>
<tr class="even">
<td align="left">precision</td>
<td align="right">0.8291502</td>
</tr>
<tr class="odd">
<td align="left">recall</td>
<td align="right">0.9147437</td>
</tr>
<tr class="even">
<td align="left">f_meas</td>
<td align="right">0.8698464</td>
</tr>
</tbody>
</table>
<p>Der er mange matricer til at validere vores model, men vi bruger dem som vi brugte
ved vores logistisk regression.</p>
<p>Modellen klare sig på lige fod med regressionsmodellen. Man kunne gå tilbage til modellen
og laver yderligere feature eengierning da det ville gøre noget for selve
præcisionen af modellen.</p>
</div>
