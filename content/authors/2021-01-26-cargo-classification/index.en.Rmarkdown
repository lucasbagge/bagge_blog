---
title: Cargo classification
author: Lucas Bagge
date: '2021-01-07'
slug: cargo-classification
categories:
  - Classification
tags:
  - Ørsted
  - Logistic regression
subtitle: ''
summary: ''
authors: []
lastmod: '2021-01-07T10:01:17+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



```{r setup, include=FALSE}
library(dplyr, warn.conflicts = FALSE)
library(knitr)
library(kableExtra, warn.conflicts = FALSE)
library(magrittr)
library(readr)
library(tidymodels)
library(skimr)
library(tidytext)
library(patchwork)


knitr::opts_chunk$set(
  cache = FALSE,
  echo = TRUE,
  dev = plot_dev,
  fig.ext = plot_ext
)

```

```{r, include=FALSE}
vessels <-
  readr::read_csv2("201123-v1-amv-vessel-tracking-labeled.csv") %>%
  mutate(quay = factor(quay, paste0("c", 835:838)),
         cargo = factor(cargo, c("WP", "WC")),
         arriving_from = factor(arriving_from)) %>%
  filter(!is.na(cargo))

n_u_call_no <- length(unique(vessels$call_no))

gross_feature_set <- tribble(
  ~ feature, ~ description,
  "eta", "Estimated time of arrival",
  "etd", "Estimated time of departure",
  "name", "Vessel name",
  "company", "The shipping company carrying out the charter",
  "arriving_from", "The location from the vessel is arriving (not necessarily the loading port)",
  "nationality", "The country under whose laws the vessel is registered or licensed",
  "vessel_type", "The types os the vessel arriving",
  "purpose", "Give us the purpose of the vessel",
  "call_no", "CM Port call number",
  "length", "Length of the vessel",
  "width", "Width of the vessel",
  "brt", "Gross Register Tonnage (GRT) of the vessel",
  "imo", "The international Maritime Organization number",
  "quay", "The quay at Amagerværket to which the vessel is assigned"
)
```

## Introduction

Amagerværket has two units 1 and 4 which produces heat and power using
respectively wood pellets and wood chips as fuel. The fuel arrives to the plant
by vessel and it is possible to track the arrivals through Copenhagen Malmö (CM)
Port's website. However, it is not directly possible to identify if the cargo of
a given ship is either wood pellets or wood chips. Consequently, the objective
is to build a model capable of classifying the vessels.

With the newly inaugurated wood chips fired unit 4 at Amagerværket and
expectedly using well above 1 Mt of wood chips per year, the plant has
suddenly---and by a substantial margin---become the largest player in the market
for wood chips delivered by vessel. To maintain market visibility and have the
best possible information to act in the biomass market, it is of importance to
BIO Markets to have information about the arrival and consumption of biomass at
Amagerværket.

The objective of this analysis is

> build a model that accurately and automatically classify vessels arriving to
> Amagerværket into groups according to cargo type

## The data set

For building our model we need to collect the [cmport
data](https://www.cmport.com/terminals/ships-in-port/). Here we have used web
scraping techniques to extract the data that is essential for us to build our
model.

The site is being updated on a regular basis, so our script that scrapes the
data is running three times a day.

As a first analysis task we need to collect information about the port and if
there were information on how we could classify the cargoes. We got great insight 
from colleagues that have tracked the cargoes for a long time and they gave us 
the information that `quay`, and `arriving from` could help us
differentiated between the cargoes.

We need to explore the data for understanding it better and look at the outcome
variable and the predictor we are considering being of most used for us.

```{r}
gross_feature_set %>% kbl() %>% kable_styling()
```

The available dataset consists of `r paste0("$N = ", n_u_call_no, "$")` 
observations of vessel arrivals---also named port calls or just calls---to
Amagerværket each with `r length(unique(vessels$call_no))` features. In the
current context not every feature is important, but those deemed important for
our model are:

* `cargo`: Specifies if the vessel carries wood chips (WC) or wood pellets (WP)
* `arriving_from`: The port/city where the cargo is being loaded
* `quay`: The quay at Amagerværket where the cargo is discharged

The `cargo` variable is our outcome variable and the one we want to classify.

### The cargo

<!-- Here we can see that there is 105 ships with WC and WP with 24. We don´t have an -->
<!-- equal amount of both cargoes and that is something that need to be considered in -->
<!-- the preprocessing step. -->

<!-- ```{r} -->
<!-- vessels %>%  -->
<!--   count(cargo) %>%    -->
<!--   ggplot(aes(x = cargo, y = n, fill = cargo)) + -->
<!--   geom_col() + -->
<!--   geom_text(aes(label = n), nudge_y = 3) + -->
<!--   labs(y = NULL, x = NULL, -->
<!--        title = "Dependent variable based on cargo", -->
<!--        subtitle = "Number of cargoes containing either WP or WC") -->
<!-- ``` -->

<!-- ### The quay at Amagerværket -->

<!-- One important predictor is `quay`. It indicate where the vessel anchor at the -->
<!-- port. Here we have four possibilities: -->

<!-- - c835 -->
<!-- - c836 -->
<!-- - c837 -->
<!-- - c838 -->

<!-- ```{r, results="hide"} -->
<!-- tbl <- addmargins(table(vessels$cargo, vessels$quay)) -->

<!-- tbl %>% -->
<!--   as.data.frame() %>% -->
<!--   pivot_wider(names_from = Var2, values_from = Freq) %>% -->
<!--   kbl(col.names = c("", colnames(tbl)), -->
<!--       caption = "Cross tabulation of cargo against quay.") %>% -->
<!--   kable_styling() -->
<!-- ``` -->

<!-- From looking at the pattern in the data and talking to colleagues there is -->
<!-- some of the quay that is a clear indicator of if the vessel is a WP or WC. -->

<!-- ```{r} -->
<!-- vessels %>% -->
<!--   count(quay) %>% -->
<!--   ggplot(aes(x = quay, y = n, fill = quay)) + -->
<!--   geom_col(position = "dodge") + -->
<!--   geom_text(aes(label = n), nudge_y = 3) + -->
<!--   labs(y = NULL, x = NULL, -->
<!--        title = "The Quay is a possible predictor",  -->
<!--        subtitle = "Number of cargoes arriving to the different quay") -->
<!-- ``` -->

<!-- Here `c838` is the quay where WP is being delivered and `c836` plus `c836` is -->
<!-- mainly WC.  -->

<!-- ```{r} -->
<!-- vessels %>%  -->
<!--   count(quay, cargo) %>%  -->
<!--   ggplot(aes(reorder_within(quay, n, cargo), n, fill = quay)) + -->
<!--   facet_grid(rows = vars(cargo), scales = 'free_y') + -->
<!--   geom_col(position = "dodge") + -->
<!--   geom_text(aes(label = n), nudge_y = 1.9) + -->
<!--   coord_flip() + -->
<!--   scale_x_reordered() + -->
<!--   labs(title = "The quay indicate what the cargo is delivering",  -->
<!--        subtitle = "Number of cargoes arriving groped by WC or WP", -->
<!--        y = "", x = "") + -->
<!--   theme(legend.title = element_blank()) -->
<!-- ``` -->

<!-- From the above plots it is clear that we can from the quay seperat what the  -->
<!-- vessel is delivering. For c837 this can be considered a joker. It lies between  -->
<!-- the end quay, so our hypothesis is that it can be considered as a waiting -->
<!-- quay where it can either be WC or WP. -->

<!-- ### The loading port of the cargo -->

<!-- Another important predictor we want to include in the models framework is  -->
<!-- `arriving_from`. This indicate where the vessel is comming from. -->
<!-- Here we want to make some investigation if we can use this as a predictor.  -->

<!-- ```{r} -->
<!-- vessels %>%  -->
<!--   group_by(arriving_from, cargo) %>%  -->
<!--   count(arriving_from, cargo)  %>%  -->
<!--   ungroup() %>%  -->
<!--   mutate(across(where(is.character), as.factor)) %>%  -->
<!--   ggplot(aes(reorder_within(arriving_from, n, cargo), n, fill = cargo)) + -->
<!--   geom_col(position = "dodge") + -->
<!--   geom_text(aes(label = n), nudge_y = 0.9) + -->
<!--   facet_wrap(~cargo, scales = "free_y") + -->
<!--   coord_flip() + -->
<!--   scale_x_reordered() + -->
<!--   scale_fill_manual(values=c("#4099DA", "#E85757")) +  -->
<!--   labs(title = "Arrival port", -->
<!--        subtitle = "Number of cargoes grouped by arriving from", -->
<!--        y = "", x = "") + -->
<!--   theme(legend.title = element_blank()) -->
<!-- ``` -->


<!-- ## Methodology -->

<!-- For solving this supervised classifications task there is different models  -->
<!-- that can be used and we did try out a logistic regression, KNN and decision tree  -->
<!-- model. In the end we went with the logistic regression for classification.  -->

<!-- In the following section we want to work though the essentiel idea behind the -->
<!-- method. -->

<!-- ### The logistic regression model -->

<!-- Logistic regression is a very popular model for classification problems and is -->
<!-- one of the most commonly used Machine Learning algorithms. It is easy -->
<!-- to implement and is often used in settings where the dataset is small or as a -->
<!-- baseline for any binary classification problem. -->

<!-- The method is used when the outcome variable is dichotomous in nature. It is a -->
<!-- special case of the general linear regression model when the outcome variable is -->
<!-- binary. -->

<!-- Let $y$ be our binary target with $y = 1$ if the vessel carries WC (the WC -->
<!-- class) and $y = 0$ if the cargo is WP (the WP class). Further, let $x$ be a -->
<!-- $M$-vector of features of the observed port calls. Then, given some available -->
<!-- information $x$, our interest lies in identifying the probability of a WC vessel -->
<!-- and by implication also the probability of a WP vessel. Hence, -->
<!-- $$ -->
<!-- \Pr(y = 1 \mid x) = \pi^c(x) = 1 - \Pr(y = 0 \mid x) = 1 - \pi^p(x) -->
<!-- $$ -->
<!-- where $\pi^c(x)$ and $\pi^p(x)$ are the conditional probabilities of observing -->
<!-- respectively a WC or a WP vessel. The probability mass function for this -->
<!-- Bernoulli distribution is -->
<!-- $$ -->
<!-- p(y \mid x) = \pi^c(x) \cdot \bigl(1 - \pi^c(x)\bigr)^{1-y}. -->
<!-- $$ -->

<!-- In order to proceed from here, one has to make assumptions about the structure -->
<!-- of the probability $\pi^c(x)$. The assumption used in the logistic regression -->
<!-- model is to proceed with a logistic function defined by -->
<!-- $$ -->
<!-- \sigma(z) = \frac{1}{1 + \exp(-z)} = \frac{\exp(z)}{\exp(z) + 1}, -->
<!-- $$ -->
<!-- with -->
<!-- $$ -->
<!-- z = \phi(x)' w -->
<!-- $$ -->
<!-- and finally impose -->
<!-- $$ -->
<!-- \pi^c(x) = \sigma(\phi(x)' w). -->
<!-- $$ -->

<!-- This equation tells that the crux of the logistic regression model is the -->
<!-- mapping of $z = \phi(x)' w$ to a "probability" through the logistic function. -->

<!-- The logistic function gives an S shape curvature. It takes any real vauled -->
<!-- number and map it into a value between 0 and 1. Here we have in mind of how the -->
<!-- probability should be interpreted. If we get an value 0.75 this mean that there -->
<!-- is 75 percent change that a cargo is WC (if WC is baseline). -->

<!-- ```{r} -->
<!-- curve({exp(x) / (1 + exp(x))}, -10, 10, xlab = "", ylab = "", -->
<!--       main = "The logistic function mapping z to the unit interval") -->
<!-- abline(v = 0, lty = "dashed") -->
<!-- ``` -->

<!-- For estimated the parameter logistic regression relies on Maximum likelihood -->
<!-- estimation (MLE). By this estimation technique the parameter is determined by -->
<!-- maximizing the log likelihood function. Here we need to use a optimization -->
<!-- algorithm for finding $w$. Often one uses Gradient acent for this purpose. -->

<!-- The coefficents should be read as log of odds so we predicts the probability of -->
<!-- occurrence of a binary event. -->

<!-- ## Analysis & results -->

<!-- For implement the logistic regression we are gonna use the software program `R` -->
<!-- and it machine learning framework `tidymodels`. tidymodels has its own unique way -->
<!-- of structuring a modelling problem and we follows that workflow. -->


<!-- ### Model formulation and data preprocessing -->

<!-- We split our data set in two sets: -->

<!-- * the *training set*: This is the bigger part of the data which we use to -->
<!--   train/estimate of our models -->
<!-- * the *test set*: This data we hold out to use for evaluation of our trained -->
<!--   models -->

<!--   Further, we divide our training set into five folds to use for evaluation of -->
<!--   the models using cross-validation.[^mdl-eval-cv] -->

<!--   [^mdl-eval-cv]: We never use a model's fit to the training set to evaluate the -->
<!--   model's performance. -->

<!-- ```{r, echo=TRUE} -->
<!-- set.seed(4595) -->

<!-- df <- vessels %>% select(cargo, arriving_from, quay) -->
<!-- df_split <- initial_split(df, prop = 0.75, strata = cargo) -->
<!-- df_train <- training(df_split) -->
<!-- df_test <- testing(df_split) -->
<!-- df_train_folds <- vfold_cv(df_train, v = 5, strata = "cargo") # FIXME  -->
<!-- ``` -->

<!-- Two model specifications are formulated. One where the cargo is predicted using -->
<!-- the quay, and one model where the cargo is predicted using the information about -->
<!-- the port where the vessel is arriving from. -->

<!-- ```{r, echo=TRUE} -->
<!-- fml_1 <- formula(cargo ~ quay) -->
<!-- fml_2 <- formula(cargo ~ arriving_from) -->
<!-- ``` -->

<!-- In the prepoceesion step we gonna use `recipe` which is part of tidymodels. Here -->
<!-- we gonna specify what we want to make of changes to the predictors and handling  -->
<!-- other issues. In that step we also could implment a method for solving the -->
<!-- imbalanced dataset problem, but because it wont give a better result we don´t  -->
<!-- add this step'.  -->

<!-- ```{r, echo=TRUE} -->
<!-- lr_1_rec <- -->
<!--   recipe(fml_1, data = df_train) %>% step_dummy(all_nominal(), -all_outcomes())   -->
<!-- lr_2_rec <- -->
<!--   recipe(fml_2, data = df_train) %>% step_dummy(all_nominal(), -all_outcomes())   -->

<!-- ``` -->


<!-- ### Logistic regression model training -->

<!-- We train a logistic regression model and use five-fold cross-validation to -->
<!-- evaluate the model fit. Here we gonna use the recipe from earlier and that and -->
<!-- the model to `workflow` which is handling the information so we easy can make -->
<!-- predictions.  -->

<!-- ```{r, echo=TRUE, warning=FALSE} -->
<!-- lr_mod <- logistic_reg() %>% set_engine("glm") -->
<!-- lr_wfl_1 <- workflow() %>% add_model(lr_mod) %>% add_recipe(lr_1_rec) -->
<!-- lr_wfl_2 <- workflow() %>% add_model(lr_mod) %>% add_recipe(lr_2_rec) -->
<!-- lr_wfls <- list(quay = lr_wfl_1, arriving_from = lr_wfl_2) -->

<!-- lr_fits_rs <- -->
<!--   lr_wfls %>% -->
<!--   imap(~ { -->
<!--     fit_resamples( -->
<!--       .x, -->
<!--       resamples = df_train_folds, -->
<!--       control = control_resamples(save_pred = TRUE) -->
<!--     ) -->
<!--   }) -->
<!-- ``` -->

<!-- For the evaluation of the model fit we use the model *accuracy* and the -->
<!-- *Receiver Operating characteristic (ROC)* curve which plots the True Positive -->
<!-- Rate (the sensitivity) against the False Positive Rate (1 - specificity/true -->
<!-- negative rate). These measures are defined  -->

<!-- $$ -->
<!-- \begin{aligned} -->
<!-- \mathrm{accuracy} &= \frac{\mathrm{TP} + \mathrm{TN}}{N} \\ -->
<!-- \text{sensitivity} &= \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}} \\ -->
<!-- \text{specificity} &= \frac{\mathrm{TN}}{\mathrm{TN} + \mathrm{FP}} -->
<!-- \end{aligned} -->
<!-- $$ -->

<!-- where $\mathrm{TP}$ is number of true WP (true positive), $\mathrm{TN}$ is the -->
<!-- number of true WC (true negative), $\mathrm{FN}$ is the number of predicted WCs -->
<!-- which really were WPs (false negative) and $\mathrm{FP}$ is the number of -->
<!-- falsely predicted WP vessels (false positive). -->

<!-- The other measure we are gonna use is the *classification accuracy*. It is -->
<!-- the fraction of predictions our model got right. -->

<!-- Figure \@ref(fig:lr-train-roc-curves) shows the trade-off between TRP and 1-FP. -->
<!-- Classifiers that give curves closer to the top-left corner indicate a better  -->
<!-- performance. Here we see that some gives a perfect prediction.  -->

<!-- ```{r lr-train-roc-curves, fig.cap="ROC curves."} -->
<!-- lr_fits_rs %>% -->
<!--   imap(~ { -->
<!--     collect_predictions(.x) %>% -->
<!--       group_by(id) %>% -->
<!--       roc_curve(truth = cargo, .pred_WP) %>% -->
<!--       autoplot() + ggtitle(.y) + theme_orsted(base_family = "") -->
<!--   }) %>% -->
<!--   reduce(`+`) -->
<!-- ``` -->

<!-- As a final clearification we can look at Table \@ref(tab:lr-train-mdl-accu)  that -->
<!-- shows us a clear picture of our cross validation and can conclude that we will -->
<!-- use quay af a predictor. -->

<!-- ```{r lr-train-mdl-accu} -->
<!-- lr_fits_rs %>% -->
<!--   imap_dfr(~ relocate(mutate(collect_metrics(.x), model = .y), model)) %>% -->
<!--   kbl(caption = "Model accuracy.") %>% kable_styling() -->
<!-- ``` -->

<!-- ### Prediction -->

<!-- Now that we have trained our model on the training data, we test how well it -->
<!-- does on the test data. We are os course certain that quay is the best predictor -->
<!-- but we are gonna show the result for both predictors.  -->

<!-- ```{r} -->
<!-- # FIXME prediction from a rank-deficient fit may be misleading. https://stackoverflow.com/a/26560328. -->
<!-- lr_fits <- lr_wfls %>% map(~ fit(., data = df_train)) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- lr_fits %>% -->
<!--   imap(~ { -->
<!--     predict(.x, df_test, type = "class") %>% -->
<!--       bind_cols(select(df_test, cargo)) %>% -->
<!--       conf_mat(truth = cargo, estimate = .pred_class) %>% -->
<!--       autoplot(type = "heatmap") + ggtitle(.y) -->
<!--   }) %>% -->
<!--   reduce(`+`) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- lr_fits %>% -->
<!--   imap_dfr(~ { -->
<!--     predict(.x, df_test, type = "prob") %>%  -->
<!--       bind_cols(select(df_test, cargo)) %>% -->
<!--       roc_curve(truth = cargo, .pred_WP) %>% -->
<!--       mutate(model = .y) -->
<!--   }) %>% -->
<!--   ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) +  -->
<!--   geom_path(lwd = 1.5, alpha = 0.8) + -->
<!--   geom_abline(lty = 3) +  -->
<!--   coord_equal() +  -->
<!--   scale_color_orsted_d() -->
<!-- ``` -->

<!-- ```{r, eval=FALSE} -->
<!-- lr_pred_prob %>% roc_auc(truth = cargo, .pred_WP) %>%  kbl() %>% kable_styling() -->
<!-- ``` -->

<!-- From the above result we see that the quay as a predictor has correctly predicted -->
<!-- every data point in our test set. -->

<!-- ## Conclusion -->

<!-- From our analysis we have created a logistic regression model that predicts if  -->
<!-- the upcomming vessel is arriving with WP or WC to CMport.  -->

<!-- Our model is using `quay` as a predictor and this give us good with a very high -->
<!-- accuracy. -->

<!-- ## Estimation results {.appendix} -->

<!-- ```{r} -->
<!-- lr_fits[[1]] %>% pull_workflow_fit() %>% tidy() %>% kbl(digits = 2) %>% kable_styling() -->
<!-- ``` -->

<!-- ```{r} -->
<!-- lr_fits[[2]] %>% pull_workflow_fit() %>% tidy() %>% kbl(digits = 2) %>% kable_styling() -->
<!-- ``` -->
