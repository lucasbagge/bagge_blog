+++
# A Demo section created with the Blank widget.
# Any elements can be added in the body: https://sourcethemes.com/academic/docs/writing-markdown-latex/
# Add more sections by duplicating this file and customizing to your requirements.

widget = "blank"  # See https://sourcethemes.com/academic/docs/page-builder/
headless = true  # This file represents a page section.
active = true # Activate this widget? true/false
weight = 60  # Order that this section will appear.

title = ""
subtitle = ""

[design]
  # Choose how many columns the section has. Valid values: 1 or 2.
  columns = "1"

[design.background]
  # Apply a background color, gradient, or image.
  #   Uncomment (by removing `#`) an option to apply it.
  #   Choose a light or dark text color by setting `text_color_light`.
  #   Any HTML color name or Hex value is valid.

  # Background color.
  # color = "navy"
  
  # Background gradient.
  # gradient_start = "DeepSkyBlue"
  # gradient_end = "SkyBlue"
  
  # Background image.
  image = ""  # Name of image in `static/img/`.
  image_darken = 0.6  # Darken the image? Range 0-1 where 0 is transparent and 1 is opaque.

  # Text color (true=light or false=dark).
  text_color_light = false

[design.spacing]
  # Customize the section spacing. Order is top, right, bottom, left.
  padding = ["100px", "120px", "100px", "120px"]

[advanced]
 # Custom CSS. 
 css_style = ""
 
 # CSS class.
 css_class = ""
+++

#### Jr. Data Scientist & Data Manager, Blackwoodseven
2020-present

* I am responsible for making the data ready for the models. This means making sure there is the
  right dimensions, updated data and correct mappings. The primary tools for
  this is `redash` (a data tool like quick sense) and `python` for
  making data check and building script for data transformation.
* The second path for me is building the models with a Baysiansk framework. Here we rely on `stan` and
  our own software. I report directly to the client and the customer success department explaining the
  models.
* In the job we use AWS cloud solutions to build our models at store data.
* I have  the main responsiable for `3` and `Oister` regarding updating data
  and building models and making sure the result is reliable. 

#### Jr. Business Analyst, Ørsted
2020-present

* I have with collaboration with my Senior Business Analyst helped transformed a conservative      department into a data minded departed relying on the newest methods and programs.
* I have build different machine learning models from scratch including collecting
  the data with web scraping. Hereafter I made the model to make classification
  on vessels type. This model was used in our **Biomass intelligence** dashboard. 
  For deploying the model I used `plumber`. 
* We are also transforming our Azure platform from showing our Shiny application
  on a local server to use Docker and Azure other
* I have introduced docker and implement a continuous pipeline for building R - packages.
* I am using **git** in Azure and a master of using the terminal for pushing, pulling
  and solving merge conflicts. 

### Analysis and post
2020-present

* I have a great love for Data Science so in 2020 I decided to create my own
  blog. My blog is my way of picking up interesting fields in the data science
  world and explore its many edges. 
* One post I have made is regarding **GDPR** where I use `tidymodels` to model
  which GDPR violations is the most expensive.
* Text mining is one edge of data science that I am extremely interesting in
  so one of my post explore how to extract data from *Trust Pilot* and build
  a `Topic model`.
* In a new series of post I will explore text mining and neural network and
  how to applied it. The first post is already available where I build a 
  `densed neural network`.
* At Ørsted I work a lot with time series and that is way I in another post 
  am looking in how to build models with `modeltime` and `timetk`.

#### Jr. Data Scientist & Data Manager, Annalect
2019-2020

* Making models for clients as Coop, Fitness World and Telenor.
* Making data check and visualizations tools. 

#### Ministry of Finance, Student Assistant
2019-2019

* I helped build the new `MAKRO` models.
* Got familiar with git, python and R.

### Bachelor Thesis nomination

* My bachelor **The economics effects of QE** was nominalted for the Central bank bachelor prize.

### Master of tidyverse

* I earn a certificate for master of the tidyverse in one of my courses. 

### Courses

* [SQL - MySQL for Data Analytics and Business Intelligence](https://www.udemy.com/course/sql-mysql-for-data-analytics-and-business-intelligence/learn/lecture/8692216#overview)
* [Text Mining and Natural Language Processing in R](https://www.udemy.com/course/text-mining-and-natural-language-processing-in-r/learn/lecture/8828048#overview)
* [Git Started with GitHub](https://www.udemy.com/course/git-started-with-github/learn/lecture/2965897#overview)
* [Machine Learning and Data Science Hands-on with Python and R](https://www.udemy.com/course/machine-learning-masterclass/learn/lecture/12220834#overview)
* [Introduction to Bayesian Statistics](https://www.udemy.com/course/introduction-to-bayesian-statistics/learn/lecture/20460081#overview)
* [R Programming for Simulation and Monte Carlo Methods](https://www.udemy.com/course/r-programming-for-simulation-and-monte-carlo-methods/learn/lecture/3563566#overview)
* Multiple `R`, `Python` and `Machine Learning` courses on [Datacamp](https://learn.datacamp.com/courses)


### TA 
2018-2019

* TA for the econ students in Linear Algebra.
* TA for the econ student in Mathematics. 

## Education

* AU, Data science, 2020-present.
* SDU, Economics, 2016-2019.